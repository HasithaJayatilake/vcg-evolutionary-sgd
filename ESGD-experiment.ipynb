{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ESGD-experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNFyHkaiEu8h",
        "outputId": "eab2dbbc-5e36-464b-fa2f-e7e20d8c245c"
      },
      "source": [
        "!pip install neat-python"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neat-python in /usr/local/lib/python3.7/dist-packages (0.92)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ09mSUFrS_M",
        "outputId": "028c35c9-f618-481b-b685-18f365797663"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mMl1OrFJ4g4"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys \n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from datetime import datetime\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S9pJuH_rgja"
      },
      "source": [
        "import sys\n",
        "import neat\n",
        "sys.path.insert(0,'/content/drive/My Drive/2. Adelaide Uni/Research Project/Evolutionary Models/Imports')\n",
        "from UpperBoundCalculator import UpperBoundCalculator\n",
        "from StatisticsReporter import StatisticsReporter\n",
        "from Reporting import StdOutReporter\n",
        "from Reporting import ReporterSet\n",
        "from Reporting import BaseReporter\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iavl692t495G"
      },
      "source": [
        "# Uploading the saved model state\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def create_mount_pydrive():\n",
        "    # 1. Authenticate and create the PyDrive client.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    u_drive = GoogleDrive(gauth)\n",
        "    return u_drive\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrDyt55lMqR"
      },
      "source": [
        "upload_drive = create_mount_pydrive()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhogmAUsCiun"
      },
      "source": [
        "from neat.graphs import feed_forward_layers\n",
        "from neat.six_util import itervalues\n",
        "\n",
        "class FeedForwardTorchNet(nn.Module):\n",
        "    \"\"\" Custom Non-Linear layer with some nodes with max aggregation \"\"\"\n",
        "    def __init__(self, inputs, outputs, node_evals):\n",
        "        data_dim = n_agents*(n_agents-1)\n",
        "        formatted_data = torch.zeros(data_dim)\n",
        "\n",
        "        self.input_nodes = inputs\n",
        "        self.output_nodes = outputs\n",
        "        \n",
        "        self.values = dict((key, 0.0) for key in inputs + outputs)\n",
        "        self.node_evals = []\n",
        "        weights_list = []\n",
        "\n",
        "        # Initializing node descriptions with trainable parameters\n",
        "        for node, act_func, agg_func, bias, response, links in node_evals:\n",
        "            bias_param = nn.Parameter(torch.tensor(bias), requires_grad=True)\n",
        "            weight_params_dict = [(i,nn.Parameter(torch.tensor(w), requires_grad=True)) for i, w in links]            \n",
        "            self.node_evals.append((node, act_func, agg_func, bias_param, weight_params_dict))\n",
        "\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        if len(self.input_nodes) != len(inputs):\n",
        "            raise RuntimeError(\"Expected {0:n} inputs, got {1:n}\".format(len(self.input_nodes), len(inputs)))\n",
        "\n",
        "        for k, v in zip(self.input_nodes, inputs):\n",
        "            self.values[k] = v\n",
        "\n",
        "        for node, act_func, agg_func, bias, links in self.node_evals:\n",
        "            node_inputs = []\n",
        "            for i, w in links:\n",
        "                node_inputs.append(self.values[i] * w)\n",
        "            s = agg_func(node_inputs)\n",
        "            self.values[node] = act_func(bias + s)\n",
        "\n",
        "        return [self.values[i] for i in self.output_nodes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL4Y7S-OWv2e"
      },
      "source": [
        "\"\"\"Implements the core evolution algorithm.\"\"\"\n",
        "from neat.math_util import mean\n",
        "from neat.six_util import iteritems, itervalues\n",
        "\n",
        "\n",
        "class CompleteExtinctionException(Exception):\n",
        "    pass\n",
        "\n",
        "class Population(object):\n",
        "    \"\"\"\n",
        "    This class implements the core evolution algorithm:\n",
        "        1. Evaluate fitness of all genomes.\n",
        "        2. Check to see if the termination criterion is satisfied; exit if it is.\n",
        "        3. Generate the next generation from the current population.\n",
        "        4. Partition the new generation into species based on genetic similarity.\n",
        "        5. Go to 1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, initial_state=None):\n",
        "        self.reporters = ReporterSet()\n",
        "        self.config = config\n",
        "        stagnation = config.stagnation_type(config.stagnation_config, self.reporters)\n",
        "        self.reproduction = config.reproduction_type(config.reproduction_config,\n",
        "                                                     self.reporters,\n",
        "                                                     stagnation)\n",
        "        if config.fitness_criterion == 'max':\n",
        "            self.fitness_criterion = max\n",
        "        elif config.fitness_criterion == 'min':\n",
        "            self.fitness_criterion = min\n",
        "        elif config.fitness_criterion == 'mean':\n",
        "            self.fitness_criterion = mean\n",
        "        elif not config.no_fitness_termination:\n",
        "            raise RuntimeError(\n",
        "                \"Unexpected fitness_criterion: {0!r}\".format(config.fitness_criterion))\n",
        "\n",
        "        if initial_state is None:\n",
        "            # Create a population from scratch, then partition into species.\n",
        "            self.population = self.reproduction.create_new(config.genome_type,\n",
        "                                                           config.genome_config,\n",
        "                                                           config.pop_size)\n",
        "            self.species = config.species_set_type(config.species_set_config, self.reporters)\n",
        "            self.generation = 0\n",
        "            self.species.speciate(config, self.population, self.generation)\n",
        "        else:\n",
        "            self.population, self.species, self.generation = initial_state\n",
        "\n",
        "        self.best_genome = None\n",
        "\n",
        "    def add_reporter(self, reporter):\n",
        "        self.reporters.add(reporter)\n",
        "\n",
        "    def remove_reporter(self, reporter):\n",
        "        self.reporters.remove(reporter)\n",
        "    \n",
        "    def run_sgd(self, epochs=5):\n",
        "        \"\"\"\n",
        "        Runs stochastic gradient-descent for a specified number of epochs \n",
        "        (default is 5).        \n",
        "        \"\"\"\n",
        "        \n",
        "        for epoch in epochs:\n",
        "            pass\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def run(self, fitness_function, n=None):\n",
        "        \"\"\"\n",
        "        Runs NEAT's genetic algorithm for at most n generations.  If n\n",
        "        is None, run until solution is found or extinction occurs.\n",
        "\n",
        "        The user-provided fitness_function must take only two arguments:\n",
        "            1. The population as a list of (genome id, genome) tuples.\n",
        "            2. The current configuration object.\n",
        "\n",
        "        The return value of the fitness function is ignored, but it must assign\n",
        "        a Python float to the `fitness` member of each genome.\n",
        "\n",
        "        The fitness function is free to maintain external state, perform\n",
        "        evaluations in parallel, etc.\n",
        "\n",
        "        It is assumed that fitness_function does not modify the list of genomes,\n",
        "        the genomes themselves (apart from updating the fitness member),\n",
        "        or the configuration object.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.config.no_fitness_termination and (n is None):\n",
        "            raise RuntimeError(\"Cannot have no generational limit with no fitness termination\")\n",
        "\n",
        "        k = 0\n",
        "        while n is None or k < n:\n",
        "            k += 1\n",
        "\n",
        "            self.reporters.start_generation(self.generation)\n",
        "\n",
        "            # Evaluate all genomes using the user-provided function.\n",
        "            fitness_function(list(iteritems(self.population)), self.config)\n",
        "\n",
        "            # Gather and report statistics.\n",
        "            best = None\n",
        "            for g in itervalues(self.population):\n",
        "                if best is None or g.fitness > best.fitness:\n",
        "                    best = g\n",
        "            self.reporters.post_evaluate(self.config, self.population, self.species, best)\n",
        "\n",
        "            # Track the best genome ever seen.\n",
        "            if self.best_genome is None or best.fitness > self.best_genome.fitness:\n",
        "                self.best_genome = best\n",
        "\n",
        "            if not self.config.no_fitness_termination:\n",
        "                # End if the fitness threshold is reached.\n",
        "                fv = self.fitness_criterion(g.fitness for g in itervalues(self.population))\n",
        "                if fv >= self.config.fitness_threshold:\n",
        "                    self.reporters.found_solution(self.config, self.generation, best)\n",
        "                    break\n",
        "\n",
        "            # Create the next generation from the current generation.\n",
        "            self.population = self.reproduction.reproduce(self.config, self.species,\n",
        "                                                          self.config.pop_size, self.generation)\n",
        "\n",
        "            # Check for complete extinction.\n",
        "            if not self.species.species:\n",
        "                self.reporters.complete_extinction()\n",
        "\n",
        "                # If requested by the user, create a completely new population,\n",
        "                # otherwise raise an exception.\n",
        "                if self.config.reset_on_extinction:\n",
        "                    self.population = self.reproduction.create_new(self.config.genome_type,\n",
        "                                                                   self.config.genome_config,\n",
        "                                                                   self.config.pop_size)\n",
        "                else:\n",
        "                    raise CompleteExtinctionException()\n",
        "\n",
        "            # Divide the new population into species.\n",
        "            self.species.speciate(self.config, self.population, self.generation)\n",
        "            upload_drive = create_mount_pydrive()\n",
        "\n",
        "            self.reporters.end_generation(self.config, self.population, self.species, upload_drive=upload_drive)\n",
        "\n",
        "\n",
        "            self.generation += 1\n",
        "\n",
        "        if self.config.no_fitness_termination:\n",
        "            self.reporters.found_solution(self.config, self.generation, self.best_genome)\n",
        "\n",
        "        return self.best_genome"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSsCxMWhEPFc",
        "outputId": "879b5f74-fcf5-434a-c268-25598019361d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test = [(1,3.0),(5,6.0)]\n",
        "test2 = [(w) for i,w in test]\n",
        "# print(torch.tensor(test2))\n",
        "param = nn.Parameter(torch.tensor(test2), requires_grad=True)\n",
        "def lelu_activation(z):\n",
        "    leaky = -0.0005\n",
        "    return z if z > 0.0 else leaky * z \n",
        "\n",
        "for j in param:\n",
        "    partial = (j*-2.0)\n",
        "    print(lelu_activation(partial))\n",
        "    break\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0030, grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdqGrt0kHpck"
      },
      "source": [
        "import gzip\n",
        "import random\n",
        "import time\n",
        "\n",
        "try:\n",
        "    import cPickle as pickle  # pylint: disable=import-error\n",
        "except ImportError:\n",
        "    import pickle  # pylint: disable=import-error\n",
        "class Checkpointer(BaseReporter):\n",
        "    \"\"\"\n",
        "    A reporter class that performs checkpointing using `pickle`\n",
        "    to save and restore populations (and other aspects of the simulation state).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, generation_interval=100, time_interval_seconds=300,\n",
        "                 filename_prefix='neat-model2-checkpoint-'):\n",
        "        \"\"\"\n",
        "        Saves the current state (at the end of a generation) every ``generation_interval`` generations or\n",
        "        ``time_interval_seconds``, whichever happens first.\n",
        "\n",
        "        :param generation_interval: If not None, maximum number of generations between save intervals\n",
        "        :type generation_interval: int or None\n",
        "        :param time_interval_seconds: If not None, maximum number of seconds between checkpoint attempts\n",
        "        :type time_interval_seconds: float or None\n",
        "        :param str filename_prefix: Prefix for the filename (the end will be the generation number)\n",
        "        \"\"\"\n",
        "        self.generation_interval = generation_interval\n",
        "        self.time_interval_seconds = time_interval_seconds\n",
        "        self.filename_prefix = filename_prefix\n",
        "\n",
        "        self.current_generation = None\n",
        "        self.last_generation_checkpoint = -1\n",
        "        self.last_time_checkpoint = time.time()\n",
        "\n",
        "    def start_generation(self, generation):\n",
        "        self.current_generation = generation\n",
        "\n",
        "    def end_generation(self, config, population, species_set, upload_drive=None):\n",
        "        checkpoint_due = False\n",
        "\n",
        "        if self.time_interval_seconds is not None:\n",
        "            dt = time.time() - self.last_time_checkpoint\n",
        "            if dt >= self.time_interval_seconds:\n",
        "                checkpoint_due = True\n",
        "\n",
        "        if (checkpoint_due is False) and (self.generation_interval is not None):\n",
        "            dg = self.current_generation - self.last_generation_checkpoint\n",
        "            if dg >= self.generation_interval:\n",
        "                checkpoint_due = True\n",
        "\n",
        "        if (checkpoint_due) and (upload_drive is not None):\n",
        "            self.save_checkpoint(config, population, species_set, self.current_generation, upload_drive)\n",
        "            self.last_generation_checkpoint = self.current_generation\n",
        "            self.last_time_checkpoint = time.time()\n",
        "\n",
        "    def save_checkpoint(self, config, population, species_set, generation, upload_drive):\n",
        "        \"\"\" Save the current simulation state. \"\"\"\n",
        "        filename = '{0}{1}'.format(self.filename_prefix, generation)\n",
        "        print(\"Saving checkpoint to {0}\".format(filename))\n",
        "\n",
        "        with gzip.open(filename, 'w', compresslevel=5) as f:\n",
        "            data = (generation, config, population, species_set, random.getstate())\n",
        "            pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        folder_id = '1NJ8abLpYebjVZscfuXmCdbrar8Gp67i2'\n",
        "        model_checkpoint = upload_drive.CreateFile({'parents':[{u'id': folder_id}]})\n",
        "        model_checkpoint.SetContentFile(filename)\n",
        "        model_checkpoint.Upload()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def restore_checkpoint(filename):\n",
        "        \"\"\"Resumes the simulation from a previous saved point.\"\"\"\n",
        "        with gzip.open(filename) as f:\n",
        "            generation, config, population, species_set, rndstate = pickle.load(f)\n",
        "            random.setstate(rndstate)\n",
        "            return Population(config, (population, species_set, generation))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvEmGvF_oIsD",
        "outputId": "445b61f1-46d9-451a-c649-bc7d428bfca8"
      },
      "source": [
        "#  Loading or starting from scratch\n",
        "option_not_set=True\n",
        "reload_mode = False\n",
        "reload_filename = ''\n",
        "stats_filepath = ''\n",
        "init_lr = 1e-3\n",
        "while (option_not_set):\n",
        "    # clear_output(wait=True)\n",
        "    print(\"Please enter number to choose model reload mode:\\n\")\n",
        "    print(\"1. Reload existing model\")\n",
        "    print(\"2. Start from scratch\\n\")\n",
        "    option = input(\"option: \")\n",
        "    if (option=='1'):\n",
        "        option_not_set = False\n",
        "        reload_mode = True\n",
        "        init_lr = 1e-5\n",
        "        print(\"\\nPlease enter filename to reload model from:\")\n",
        "        reload_filename = input(\"filename: \")\n",
        "        print(f'Loading population from {reload_filename} ...')\n",
        "        # Loading trained model\n",
        "        drive.mount('/content/gdrive', force_remount=True)\n",
        "        GDRIVE_DIR = \"gdrive/My Drive/2. Adelaide Uni/Research Project/Evolutionary Models/Checkpoints\"\n",
        "        restored_population = Checkpointer.restore_checkpoint(os.path.join(GDRIVE_DIR, reload_filename))\n",
        "\n",
        "        print(\"Please enter filename for model stats\")        \n",
        "        stats_filename = input(\"filename for model stats: \")\n",
        "        stats_filepath = os.path.join(GDRIVE_DIR, \"Stats/\"+stats_filename)    \n",
        "        stats_reporter = StatisticsReporter(generation_interval=20, filename_prefix='neat-model2-stats-checkpoint-')\n",
        "        restore_checkpoint_result = stats_reporter.restore_checkpoint(stats_filepath)\n",
        "        if restore_checkpoint_result==0:\n",
        "            break\n",
        "        else:\n",
        "            print(restore_checkpoint_result)\n",
        "    elif (option=='2'):\n",
        "        option_not_set = False\n",
        "        print(\"Starting model from scratch!\\n\")\n",
        "        init_lr = 1e-4\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid input, try again!\\n\")\n",
        "        continue\n",
        "\n",
        "# neat-model2-stats-checkpoint-999\n",
        "# neat-model2-checkpoint-999"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter number to choose model reload mode:\n",
            "\n",
            "1. Reload existing model\n",
            "2. Start from scratch\n",
            "\n",
            "option: 2\n",
            "Starting model from scratch!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0IQrcYdJCd"
      },
      "source": [
        "if (reload_mode):\n",
        "    for n, genome in enumerate(stats_reporter.most_fit_genomes):\n",
        "        print(f'Generation {n}:{genome.fitness}')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIxP3-x5c7Jd",
        "outputId": "9a6ee8c4-1bdf-49c6-ac25-bbc21c4f381a"
      },
      "source": [
        "ONE = torch.tensor(1)\n",
        "ZERO = torch.tensor(0)\n",
        "INF = sys.maxsize\n",
        "n_agents = 4\n",
        "# Simulated data for n agents \n",
        "agent_bid_data = torch.FloatTensor(15000,n_agents).uniform_(0, 1)\n",
        "test_bid_data = torch.FloatTensor(10000,n_agents).uniform_(0, 1)\n",
        "agent_bid_data"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0681, 0.1475, 0.3616, 0.4095],\n",
              "        [0.4880, 0.5210, 0.9542, 0.4104],\n",
              "        [0.6222, 0.9126, 0.0155, 0.8031],\n",
              "        ...,\n",
              "        [0.5433, 0.3059, 0.4356, 0.1725],\n",
              "        [0.6141, 0.2940, 0.7490, 0.1963],\n",
              "        [0.2527, 0.9926, 0.6239, 0.1847]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWJJ45KudDIH"
      },
      "source": [
        "def input_formatter(data):\n",
        "  # Input data has to be in the form of pairs of other peoples bids (for each person)\n",
        "  data_dim = n_agents*(n_agents-1)\n",
        "  formatted_data = torch.zeros(data_dim)\n",
        "\n",
        "  for i, bid_set in enumerate(data):\n",
        "    input_vector = torch.tensor([])\n",
        "    for j, bid in enumerate(bid_set):\n",
        "      input_vector = torch.cat((input_vector,bid_set[:j], bid_set[j+1:]), 0)\n",
        "    # print(input_vector.shape)\n",
        "    formatted_data = torch.vstack((formatted_data,input_vector))\n",
        "\n",
        "  return formatted_data[1:]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6auWu3vrdHK0"
      },
      "source": [
        "input_data = input_formatter(agent_bid_data)\n",
        "test_data = input_formatter(test_bid_data)\n",
        "input_data_np = input_data.detach().cpu().numpy()\n",
        "test_data_np = test_data.detach().cpu().numpy()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO2q7tF7fuMY"
      },
      "source": [
        "def vcg_constraints (values, rebates, verbose=False):\n",
        "    num_agents = values.shape[0]    \n",
        "    best_utility = max(values.sum(),1)\n",
        "    project_utility = (num_agents)*best_utility\n",
        "    achieved_utility = project_utility-rebates.sum()\n",
        "    efficiency_ratio = achieved_utility/best_utility\n",
        "    efficiency_constraint = rebates.sum() - ((num_agents - efficiency_ratio)*best_utility)\n",
        "    budget_constraint = ((num_agents-1)*best_utility)-rebates.sum()\n",
        " \n",
        "    if verbose:\n",
        "      print('num_agents: ', num_agents)\n",
        "      print('sum of bids: ', values.sum())\n",
        "      print('sum of rebates: ', rebates.sum())\n",
        "      print('best_utility: ', best_utility)\n",
        "      print('project_utility: ', project_utility)\n",
        "      print('achieved_utility: ', achieved_utility)\n",
        "      print('efficiency_ratio: ', efficiency_ratio)\n",
        "      print('budget_constraint: ', budget_constraint)\n",
        " \n",
        "    return budget_constraint, efficiency_constraint, efficiency_ratio"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm-ysJF3XlDe",
        "outputId": "629a5d97-0cc9-449d-947b-b14ad8426f1f"
      },
      "source": [
        "uc = UpperBoundCalculator(n_agents)\n",
        "upper_bound = uc.get_upper_bound()\n",
        "print(f'Conjectured upper bound worst-case alpha for {n_agents} agents: {upper_bound}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conjectured upper bound worst-case alpha for 4 agents: 0.6666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuloCZ7Lz9FY"
      },
      "source": [
        "def eval_single_genome(net, marker):\n",
        "  max_budget_constraint = -INF\n",
        "  max_efficiency_constraint = -INF\n",
        "  worst_case_efficiency = INF\n",
        "  for project in input_data_np:\n",
        "    X = project\n",
        "    output = net.activate(X[:marker])\n",
        "    for i in range(marker):\n",
        "      start = marker*(i+1)\n",
        "      end = marker*(i+2)\n",
        "      output_ = net.activate(X[start:end])\n",
        "      output = np.concatenate((output, output_))\n",
        "    budget_constraint, efficiency_constraint, efficiency_ratio = vcg_constraints(X[:n_agents], output)\n",
        "    max_budget_constraint = max(max_budget_constraint, budget_constraint)\n",
        "    max_efficiency_constraint = max(max_efficiency_constraint, efficiency_constraint)\n",
        "    worst_case_efficiency =  min(worst_case_efficiency, efficiency_ratio)\n",
        "\n",
        "  return max_budget_constraint, max_efficiency_constraint, worst_case_efficiency\n",
        "\n",
        "def wc_efficiency_reward_function(wc_efficiency, ub):\n",
        "    if wc_efficiency<0:\n",
        "        return wc_efficiency*10\n",
        "    else:\n",
        "        return min(wc_efficiency, ub)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LyPUrsTcM-6"
      },
      "source": [
        "def eval_genomes_vcg(genomes, config):\n",
        "    marker = n_agents-1\n",
        "    budget_surplus_allowance = 0.1\n",
        "    efficiency_surplus_allowance = 0.1\n",
        "    constraint_surplus = budget_surplus_allowance + budget_surplus_allowance\n",
        "    best_wc_budget_constraint = INF\n",
        "    best_wc_efficiency_constraint = INF\n",
        "    best_wc_efficiency = -INF\n",
        "    best_fitness = -INF\n",
        "    best_genome=None\n",
        "\n",
        "    for genome_id, genome in genomes:\n",
        "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
        "        max_budget_constraint, max_efficiency_constraint, worst_case_efficiency = eval_single_genome(net, marker)\n",
        "        penalty1 = 100*max_budget_constraint if max_budget_constraint>0 else (1e-2)*max_budget_constraint\n",
        "        penalty2 = 10*max_efficiency_constraint if max_efficiency_constraint>0 else 0  \n",
        "        genome.fitness = wc_efficiency_reward_function(worst_case_efficiency, upper_bound) - penalty1 - penalty2\n",
        "        if genome.fitness>best_fitness:\n",
        "            best_fitness = genome.fitness\n",
        "            best_genome = genome\n",
        "            best_wc_budget_constraint = max_budget_constraint\n",
        "            best_wc_efficiency_constraint = max_efficiency_constraint\n",
        "            best_wc_efficiency = worst_case_efficiency\n",
        "    \n",
        "    print('Best budget constraint: {0:3.5f}'.format(best_wc_budget_constraint))    \n",
        "    print('Best efficiency constraint: {0:3.5f}'.format(best_wc_efficiency_constraint))    \n",
        "    print('Best worst-case efficiency: {0:3.5f}'.format(best_wc_efficiency))\n",
        "\n",
        "\n",
        "def lelu_activation(z):\n",
        "        leaky = -0.0005\n",
        "        return z if z > 0.0 else leaky * z    \n",
        "\n",
        "def run_vcg(config_file, n_agents, stats=None, restore_mode=False, restored_population=None):\n",
        "    marker = n_agents-1\n",
        "    # Load configuration.\n",
        "    \n",
        "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
        "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
        "                         config_file)\n",
        "\n",
        "    config.genome_config.activation_defs.add('lelu', lelu_activation)\n",
        "    # Create the population, which is the top-level object for a NEAT run.\n",
        "    if (restore_mode):\n",
        "        p = restored_population\n",
        "    else:\n",
        "        p = Population(config)\n",
        "\n",
        "    # Add a stdout reporter to show progress in the terminal.\n",
        "    p.add_reporter(StdOutReporter(True))\n",
        "    if (restore_mode):\n",
        "        p.add_reporter(stats)\n",
        "    else:\n",
        "        stats=StatisticsReporter(generation_interval=20, filename_prefix='neat-model2-stats-checkpoint-')\n",
        "        p.add_reporter(stats)\n",
        "    p.add_reporter(Checkpointer(generation_interval=20, time_interval_seconds=None, filename_prefix='neat-model2-checkpoint-'))\n",
        "\n",
        "    \n",
        "    # Run for specified number of generations.\n",
        "    # winner = p.run(eval_genomes_vcg, 1)\n",
        "\n",
        "    # Display the winning genome.\n",
        "    # print('\\nBest genome:\\n{!s}'.format(winner))\n",
        "\n",
        "    # for n, genome in enumerate(stats.most_fit_genomes):\n",
        "    #     print(f'Generation {n}:{genome.fitness}')\n",
        "\n",
        "    return p\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBem_Am6PBUK",
        "scrolled": false,
        "outputId": "da8b013c-d7a3-4e6f-ada3-71ea48f11132"
      },
      "source": [
        "# Loading config file\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "GDRIVE_DIR = \"gdrive/My Drive/2. Adelaide Uni/Research Project/Evolutionary Models/Imports\"\n",
        "config_filename = \"public-project-config-two.py\"\n",
        "session_config_filename = os.path.join(GDRIVE_DIR, config_filename)\n",
        "\n",
        "if (reload_mode):\n",
        "    population = run_vcg(session_config_filename, n_agents, stats_reporter, restore_mode=True, restored_population=restored_population)\n",
        "else:\n",
        "    population = run_vcg(session_config_filename, n_agents)\n",
        " \n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7dggJi-BfqG"
      },
      "source": [
        "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
        "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
        "                         session_config_filename)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VORtD7IWNzXF",
        "outputId": "63fe7d9a-99aa-4aab-b4d5-19a1a3e7e4f1"
      },
      "source": [
        "print(config.genome_config.input_keys)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1, -2, -3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaRUHYBzASvG",
        "outputId": "2d6362d7-078f-423d-c3bb-1d5aa6e642f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(config.genome_config.output_keys + config.genome_config.input_keys)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, -1, -2, -3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGJLepmP_1Up",
        "outputId": "51fcefc0-8a72-482a-d3d4-48f4fe635351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "values = dict((key, 0.0) for key in config.genome_config.output_keys + config.genome_config.input_keys)\n",
        "print(values)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.0, -1: 0.0, -2: 0.0, -3: 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKYXw7yzAyY",
        "outputId": "b90c0178-7542-4ade-9044-ca248383c908"
      },
      "source": [
        "# for v in list():\n",
        "def lelu_activation(z):\n",
        "    leaky = -0.0005\n",
        "    return z if z > 0.0 else leaky * z\n",
        "\n",
        "config.genome_config.activation_defs.add('lelu', lelu_activation)\n",
        "print(config.genome_config.activation_defs.get('lelu'))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function lelu_activation at 0x7f5f5c3c2050>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3KngyJtuQoa",
        "outputId": "87fa045d-bec6-45ba-84bd-3cf3e9e64e76"
      },
      "source": [
        "\n",
        "\n",
        "for _,genome in population.population.items():\n",
        "    print(genome)\n",
        "    # net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
        "    # print(net)\n",
        "    # for _, node in genome.nodes.items():\n",
        "    #     print(node.bias)\n",
        "\n",
        "    # print(\"\\n\")\n",
        "    for _, connection in genome.connections.items():\n",
        "        print(connection.key)\n",
        "    break\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key: 1\n",
            "Fitness: None\n",
            "Nodes:\n",
            "\t0 DefaultNodeGene(key=0, bias=1.0043693611911402, response=1.0, activation=relu, aggregation=sum)\n",
            "\t1 DefaultNodeGene(key=1, bias=0.6742478338113818, response=1.0, activation=relu, aggregation=sum)\n",
            "Connections:\n",
            "\tDefaultConnectionGene(key=(-3, 1), weight=-0.009179803920207088, enabled=True)\n",
            "\tDefaultConnectionGene(key=(-2, 1), weight=-0.0012709668562062393, enabled=True)\n",
            "\tDefaultConnectionGene(key=(-1, 1), weight=0.012639299824341761, enabled=True)\n",
            "\tDefaultConnectionGene(key=(1, 0), weight=-0.005545537219766273, enabled=True)\n",
            "(-1, 1)\n",
            "(-2, 1)\n",
            "(-3, 1)\n",
            "(1, 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_1EYT5j49fS"
      },
      "source": [
        "# best_genome = evolution_stats.best_genome()\n",
        "# marker  = n_agents-1\n",
        "# config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
        "#                          neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
        "#                          session_config_filename)\n",
        "# best_net = neat.nn.FeedForwardNetwork.create(best_genome, config)\n",
        "# max_budget_constraint, max_efficiency_constraint, worst_case_efficiency = eval_single_genome(best_net, marker)\n",
        "# penalty1 = 100*max_budget_constraint if max_budget_constraint>0 else 0 \n",
        "# penalty2 = 100*max_efficiency_constraint if max_efficiency_constraint>0 else 0  \n",
        "# best_fitness = min(worst_case_efficiency, upper_bound) - penalty1 - penalty2\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hzwVgLzDp3n"
      },
      "source": [
        "# print('max_budget_constraint: ', max_budget_constraint)\n",
        "# print('max_efficiency_constraint: ', max_efficiency_constraint)\n",
        "# print('worst_case_efficiency: ', worst_case_efficiency)\n",
        "# print('best_fitness: ', best_fitness)"
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}